/*
核心目的: 该脚本追踪内核的 futex 系统调用，统计线程因争抢锁而陷入睡眠的频率和时长。

使用方法: 1. 启动压测程序，获取 PID (例如 12345) 2. 运行脚本 sudo ./analyze_lock.bt -p 12345

关键指标解读: 
@total_waits: 进程内所有线程触发内核态锁等待的总次数。
@wait_ns: 等待耗时的直方图。
RocksDB: 通常呈现长尾分布（毫秒级），说明发生了严重的 Convoy Effect（护航效应）。
TitanKV: 应集中在微秒级（主要来自 Client 端的内存分配锁），Worker 线程应接近 0。
@waits_by_tid: 按线程 ID 统计。CoreWorker 线程的计数应极低。

案例：TitanKV vs RocksDB 实战对比
以下数据采集自 4 核 VM 环境，4KB 随机写入场景。
1. 锁竞争 (Futex Wait)
RocksDB (Sync模式): 触发了 **28241次** 内核锁等待，长尾延迟高达 **2ms**。
TitanKV: 触发了 **16890次** 等待（主要来自测试框架本身），P99 延迟稳定在 500us 以下。Worker 线程零竞争。
2. 上下文切换 (Context Switch)
RocksDB: 总计 **315728** 次切换 (Involuntary Context Switches)。CPU 大量时间浪费在调度上。
TitanKV: 总计 **26862** 次切换。TPC 绑核策略成功减少了 **91%** 的调度开销。
(详细输出见项目根目录 docs/titanvsrocsdb.md)
*/

#!/usr/bin/env bpftrace
#include <linux/futex.h>

BEGIN
{
    printf("Tracing FUTEX_WAIT contention for PID %d...\n", pid);
    printf("Hit Ctrl-C to end.\n\n");
}

tracepoint:syscalls:sys_enter_futex
/ pid == (uint64)pid &&
  ((args->op & FUTEX_CMD_MASK) == FUTEX_WAIT ||
   (args->op & FUTEX_CMD_MASK) == FUTEX_WAIT_BITSET) /
{
    @wait_start[tid] = nsecs;
    @wait_addr[tid]  = args->uaddr;
}

tracepoint:syscalls:sys_exit_futex
/ pid == (uint64)pid && @wait_start[tid] /
{
    $delta = nsecs - @wait_start[tid];

    @wait_ns = hist($delta);
    @wait_count[@wait_addr[tid]] += 1;
    @wait_time_ns[@wait_addr[tid]] += $delta;

    @total_waits += 1;          /* 全局锁等待总次数 */
    @waits_by_tid[tid] += 1;    /* 每个线程的等待次数 */

    delete(@wait_start[tid]);
    delete(@wait_addr[tid]);
}

END
{
    printf("\n========== Futex Contention Summary (PID %d) ==========\n\n", pid);

    printf("---- Total Futex Wait Count ----\n");
    print(@total_waits);

    printf("\n---- Futex Wait Latency Histogram (ns) ----\n");
    print(@wait_ns);

    printf("\n---- Futex Wait Count by Address ----\n");
    print(@wait_count);

    printf("\n---- Futex Total Wait Time by Address (ns) ----\n");
    print(@wait_time_ns);

    printf("\n---- Futex Wait Count by Thread ----\n");
    print(@waits_by_tid);
}
